{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bba0e73",
   "metadata": {},
   "source": [
    "# Gender Classification\n",
    "\n",
    "In an attempt to analyze the way in which movie characters speak about male characters versus female characters, we try to classify the gender of the character being spoken about in a particular movie line sentence.\n",
    "\n",
    "Here is an outline of our approach:\n",
    "1. Process the `data/movie_lines.txt` file from the Cornell Movie Dialogs Corpus.\n",
    "    * Perform sentence segmentation on each movie line to determine where the sentence boundaries are for each line\n",
    "    * Separate each sentence of a movie line onto its own row in a Pandas dataframe.\n",
    "    * Tokenize each movie line sentence to obtain a list of words for each sentence.\n",
    "    * For each movie line sentence, determine whether there is a 'he' or 'she' pronoun in it.\n",
    "2. Write all 23990 sentences with 'he' (and not both 'he' and 'she') to `data_processed/movie_line_sentences_tokenized_he.txt`.\n",
    "3. Write all 10735 sentences with 'she' (and not both 'he' and 'she') to `data_processed/movie_line_sentences_tokenized_she.txt`.\n",
    "4. To achieve gender parity, use all 10735 of the 'she' sentences, and randomly choose 10735 of the 'he' sentences to be in the dataset used for this classification task. Write those 10735 'he' sentences to `data_processed/movie_line_sentences_tokenized_he_selected.txt`.\n",
    "5. Build a vocabulary of all the words in those 10735 'he' sentences and 10735 'she' sentences.\n",
    "    * Write this vocabulary to `data_processed/movie_line_sentences_vocab.txt`, where each vocab word should appear on its own line.\n",
    "6. Limit the vocab size to the top 10000 vocab words after removing the 100 most common stop words.\n",
    "    * 'he' and 'she' are included in the 100 most common stop words, so this also helps us avoid using 'he' or 'she' as features.\n",
    "    * 'he' is generally used to describe men and 'she' is generally used to describe women, so we didn't want to include these two pronouns as features in our model, since it would not tell us much about the words used to describe male characters versus female characters if 'he' and 'she' were the most important features in our model.\n",
    "7. For each movie line sentence, obtain a feature vector. Use the counts of each unigram in the sentence as bag-of-words features. Populate a scikit-learn sparse feature matrix with the feature vectors for all 10735 'he' sentences and 10735 'she' sentences. The first 10735 feature vectors of the feature matrix are for the 'he' sentences, and the last 10735 feature vectors are for the 'she' sentences.\n",
    "8. Create a ground truth list of 0 and 1 labels, where the first 10735 labels are 0's, and the last 10735 labels are 1's.\n",
    "    * 0 is for 'he'\n",
    "    * 1 is for 'she'\n",
    "9. Create a scikit-learn Multinomial Bayes Naive Classifier.\n",
    "10. Perform 10-fold cross validation using scikit-learn's `cross_val_predict` function, passing in the feature matrix, the ground truth label list, and 10 as the number of folds. Write binary predictions (0 or 1) and prediction probabilities for all 10735 'he' sentences and 10735 'she' sentences to `data_processed/movie_line_sentences_predictions.txt` file.\n",
    "11. Calculate accuracy, precision, recall, and F1 by comparing the binary predictions in `data_processed/movie_line_sentences_predictions.txt` to the ground truth labels in our ground truth label list, matching movie line sentences by their index (which should be the same for the same sentence in the prediction file and the ground truth label list)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbc33d7",
   "metadata": {},
   "source": [
    "## Step 1: Process the `data/movie_lines.txt` file from the Cornell Movie Dialogs Corpus\n",
    "\n",
    "* Perform sentence segmentation on each movie line to determine where the sentence boundaries are for each line\n",
    "* Separate each sentence of a movie line onto its own row in a Pandas dataframe.\n",
    "* Tokenize each movie line sentence to obtain a list of words for each sentence.\n",
    "* For each movie line sentence, determine whether there is a 'he' or 'she' pronoun in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16fbec24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80ed7549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So we can see the entire movie line in the dataframe\n",
    "# Important for writing movie line sentences to files later in this step!\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9172197d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import movie_lines.txt data as pandas dataframe\n",
    "movie_lines_features = [\"LineID\", \"Character\", \"Movie\", \"Name\", \"Line\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f27007b",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_lines = pd.read_csv(\"data/movie_lines.txt\", sep = \"\\+\\+\\+\\$\\+\\+\\+\", engine = \"python\", encoding='ISO-8859-1', index_col = False, names = movie_lines_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5579aba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LineID</th>\n",
       "      <th>Character</th>\n",
       "      <th>Movie</th>\n",
       "      <th>Name</th>\n",
       "      <th>Line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L1045</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>They do not!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L1044</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>They do to!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L985</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>I hope so.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L984</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>She okay?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L925</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>Let's go.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LineID Character Movie       Name           Line\n",
       "0  L1045        u0    m0     BIANCA    They do not!\n",
       "1  L1044        u2    m0    CAMERON     They do to!\n",
       "2   L985        u0    m0     BIANCA      I hope so.\n",
       "3   L984        u2    m0    CAMERON       She okay?\n",
       "4   L925        u0    m0     BIANCA       Let's go."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92f8e8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip the space from \"LineID\" for further usage\n",
    "movie_lines[\"LineID\"] = movie_lines[\"LineID\"].apply(str.strip)\n",
    "\n",
    "# Change the datatype of \"Line\" to string and lowercase \"Line\"\n",
    "movie_lines[\"Line\"] = movie_lines[\"Line\"].apply(str)\n",
    "movie_lines[\"Line\"] = movie_lines[\"Line\"].apply(str.lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "263b0ca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LineID</th>\n",
       "      <th>Character</th>\n",
       "      <th>Movie</th>\n",
       "      <th>Name</th>\n",
       "      <th>Line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L1045</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>they do not!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L1044</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>they do to!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L985</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>i hope so.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L984</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>she okay?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L925</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>let's go.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  LineID Character Movie       Name           Line\n",
       "0  L1045       u0    m0     BIANCA    they do not!\n",
       "1  L1044       u2    m0    CAMERON     they do to!\n",
       "2   L985       u0    m0     BIANCA      i hope so.\n",
       "3   L984       u2    m0    CAMERON       she okay?\n",
       "4   L925       u0    m0     BIANCA       let's go."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b43412b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/michellelum/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk will be used for sentence segmentation and word tokenization\n",
    "import nltk\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19817956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform sentence segmentation on each movie line\n",
    "# Segmented_Line column will contain a list of the sentences in the movie line\n",
    "movie_lines[\"Segmented_Line\"] = movie_lines[\"Line\"].apply(sent_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33ae6558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The next few cells modify movie_lines dataframe so each movie line sentence is on its own row\n",
    "df_temp = pd.DataFrame(columns=movie_lines.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70058824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LineID</th>\n",
       "      <th>Character</th>\n",
       "      <th>Movie</th>\n",
       "      <th>Name</th>\n",
       "      <th>Line</th>\n",
       "      <th>Segmented_Line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [LineID, Character, Movie, Name, Line, Segmented_Line]\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3abddc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in movie_lines.iterrows():\n",
    "    for sentence in row[1][\"Segmented_Line\"]:\n",
    "        line_id = row[1][\"LineID\"]\n",
    "        character = row[1][\"Character\"]\n",
    "        movie = row[1][\"Movie\"]\n",
    "        name = row[1][\"Name\"]\n",
    "        line = row[1][\"Line\"]\n",
    "        segmented = sentence\n",
    "        new_row = {\"LineID\":line_id, \"Character\": character,\n",
    "                   \"Movie\":movie,\"Name\":name,\"Line\":line,\n",
    "                   \"Segmented_Line\":segmented}\n",
    "        df_temp = df_temp.append(new_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7feff492",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_lines = df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d15b7ace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LineID</th>\n",
       "      <th>Character</th>\n",
       "      <th>Movie</th>\n",
       "      <th>Name</th>\n",
       "      <th>Line</th>\n",
       "      <th>Segmented_Line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L1045</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>they do not!</td>\n",
       "      <td>they do not!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L1044</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>they do to!</td>\n",
       "      <td>they do to!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L985</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>i hope so.</td>\n",
       "      <td>i hope so.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L984</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>she okay?</td>\n",
       "      <td>she okay?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L925</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>let's go.</td>\n",
       "      <td>let's go.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  LineID Character Movie       Name           Line Segmented_Line\n",
       "0  L1045       u0    m0     BIANCA    they do not!   they do not!\n",
       "1  L1044       u2    m0    CAMERON     they do to!    they do to!\n",
       "2   L985       u0    m0     BIANCA      i hope so.     i hope so.\n",
       "3   L984       u2    m0    CAMERON       she okay?      she okay?\n",
       "4   L925       u0    m0     BIANCA       let's go.      let's go."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46ecc660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(510511, 6)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_lines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f343a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize each movie line sentence\n",
    "# Tokenized_Line column will contain a list of the words in the movie line sentence in that row\n",
    "movie_lines[\"Tokenized_Line\"] = movie_lines[\"Segmented_Line\"].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8867765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LineID</th>\n",
       "      <th>Character</th>\n",
       "      <th>Movie</th>\n",
       "      <th>Name</th>\n",
       "      <th>Line</th>\n",
       "      <th>Segmented_Line</th>\n",
       "      <th>Tokenized_Line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L1045</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>they do not!</td>\n",
       "      <td>they do not!</td>\n",
       "      <td>[they, do, not, !]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L1044</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>they do to!</td>\n",
       "      <td>they do to!</td>\n",
       "      <td>[they, do, to, !]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L985</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>i hope so.</td>\n",
       "      <td>i hope so.</td>\n",
       "      <td>[i, hope, so, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L984</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>she okay?</td>\n",
       "      <td>she okay?</td>\n",
       "      <td>[she, okay, ?]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L925</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>let's go.</td>\n",
       "      <td>let's go.</td>\n",
       "      <td>[let, 's, go, .]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  LineID Character Movie       Name           Line Segmented_Line  \\\n",
       "0  L1045       u0    m0     BIANCA    they do not!   they do not!   \n",
       "1  L1044       u2    m0    CAMERON     they do to!    they do to!   \n",
       "2   L985       u0    m0     BIANCA      i hope so.     i hope so.   \n",
       "3   L984       u2    m0    CAMERON       she okay?      she okay?   \n",
       "4   L925       u0    m0     BIANCA       let's go.      let's go.   \n",
       "\n",
       "       Tokenized_Line  \n",
       "0  [they, do, not, !]  \n",
       "1   [they, do, to, !]  \n",
       "2    [i, hope, so, .]  \n",
       "3      [she, okay, ?]  \n",
       "4    [let, 's, go, .]  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50d55915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(510511, 7)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_lines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd2dae59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that takes in a tokenized_line as a list of words\n",
    "# Returns 'he & she' if both 'he' and 'she' are in tokenized_line\n",
    "# Returns 'he' if only 'he' is in tokenized_line\n",
    "# Returns 'she' if only 'she' is in tokenized_line\n",
    "# Returns 'none' if neither 'he' nor 'she' is in tokenized_line\n",
    "def get_pronoun(tokenized_line):\n",
    "    if \"he\" in tokenized_line and \"she\" in tokenized_line:\n",
    "        return \"he & she\"\n",
    "    elif \"he\" in tokenized_line:\n",
    "        return \"he\"\n",
    "    elif \"she\" in tokenized_line:\n",
    "        return \"she\"\n",
    "    else:\n",
    "        return \"none\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "559b4654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find 'he' or 'she' pronoun(s) in each movie line sentence\n",
    "# Pronoun column will contain\n",
    "# 'he & she' if both 'he' and 'she' are in tokenized_line\n",
    "# 'he' if only 'he' is in tokenized_line\n",
    "# 'she' if only 'she' is in tokenized_line\n",
    "# 'none' if neither 'he' nor 'she' is in tokenized_line\n",
    "movie_lines[\"Pronoun\"] = movie_lines[\"Tokenized_Line\"].apply(get_pronoun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70d7c91f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LineID</th>\n",
       "      <th>Character</th>\n",
       "      <th>Movie</th>\n",
       "      <th>Name</th>\n",
       "      <th>Line</th>\n",
       "      <th>Segmented_Line</th>\n",
       "      <th>Tokenized_Line</th>\n",
       "      <th>Pronoun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L1045</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>they do not!</td>\n",
       "      <td>they do not!</td>\n",
       "      <td>[they, do, not, !]</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L1044</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>they do to!</td>\n",
       "      <td>they do to!</td>\n",
       "      <td>[they, do, to, !]</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L985</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>i hope so.</td>\n",
       "      <td>i hope so.</td>\n",
       "      <td>[i, hope, so, .]</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L984</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>she okay?</td>\n",
       "      <td>she okay?</td>\n",
       "      <td>[she, okay, ?]</td>\n",
       "      <td>she</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L925</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>let's go.</td>\n",
       "      <td>let's go.</td>\n",
       "      <td>[let, 's, go, .]</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  LineID Character Movie       Name           Line Segmented_Line  \\\n",
       "0  L1045       u0    m0     BIANCA    they do not!   they do not!   \n",
       "1  L1044       u2    m0    CAMERON     they do to!    they do to!   \n",
       "2   L985       u0    m0     BIANCA      i hope so.     i hope so.   \n",
       "3   L984       u2    m0    CAMERON       she okay?      she okay?   \n",
       "4   L925       u0    m0     BIANCA       let's go.      let's go.   \n",
       "\n",
       "       Tokenized_Line Pronoun  \n",
       "0  [they, do, not, !]    none  \n",
       "1   [they, do, to, !]    none  \n",
       "2    [i, hope, so, .]    none  \n",
       "3      [she, okay, ?]     she  \n",
       "4    [let, 's, go, .]    none  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b40dc68b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(510511, 8)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_lines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e05e84d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note from michelle: this doesn't seem to work?\n",
    "\n",
    "# Write the whole movie_lines dataframe to a txt file\n",
    "# with open('data_processed/movie_lines_df.txt', 'w') as f:\n",
    "#    movie_lines_string = movie_lines.to_string(header=False, index=False)\n",
    "#    f.write(movie_lines_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a4f2ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write each movie line sentence to its own line in movie_line_sentences.txt\n",
    "with open('data_processed/movie_line_sentences.txt', 'w') as f:\n",
    "    movie_lines_string = movie_lines['Segmented_Line'].to_string(header=False, index=False)\n",
    "    f.write(movie_lines_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac4e0d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write each tokenized movie line sentence to its own line in movie_line_sentences_tokenized.txt\n",
    "with open('data_processed/movie_line_sentences_tokenized.txt', 'w') as f:\n",
    "    movie_lines_string = movie_lines['Tokenized_Line'].to_string(header=False, index=False)\n",
    "    f.write(movie_lines_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2e9a74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all rows where the movie line sentence does not contain either 'he' or 'she'\n",
    "movie_lines = movie_lines.loc[movie_lines[\"Pronoun\"] != \"none\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f8013b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LineID</th>\n",
       "      <th>Character</th>\n",
       "      <th>Movie</th>\n",
       "      <th>Name</th>\n",
       "      <th>Line</th>\n",
       "      <th>Segmented_Line</th>\n",
       "      <th>Tokenized_Line</th>\n",
       "      <th>Pronoun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L984</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>she okay?</td>\n",
       "      <td>she okay?</td>\n",
       "      <td>[she, okay, ?]</td>\n",
       "      <td>she</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>L407</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>who knows?  all i've ever heard her say is that she'd dip before dating a guy that smokes.</td>\n",
       "      <td>all i've ever heard her say is that she'd dip before dating a guy that smokes.</td>\n",
       "      <td>[all, i, 've, ever, heard, her, say, is, that, she, 'd, dip, before, dating, a, guy, that, smokes, .]</td>\n",
       "      <td>she</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>L406</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>so that's the kind of guy she likes? pretty ones?</td>\n",
       "      <td>so that's the kind of guy she likes?</td>\n",
       "      <td>[so, that, 's, the, kind, of, guy, she, likes, ?]</td>\n",
       "      <td>she</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>L405</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>lesbian?  no. i found a picture of jared leto in one of her drawers, so i'm pretty sure she's not harboring same-sex tendencies.</td>\n",
       "      <td>i found a picture of jared leto in one of her drawers, so i'm pretty sure she's not harboring same-sex tendencies.</td>\n",
       "      <td>[i, found, a, picture, of, jared, leto, in, one, of, her, drawers, ,, so, i, 'm, pretty, sure, she, 's, not, harboring, same-sex, tendencies, .]</td>\n",
       "      <td>she</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>L404</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>she's not a...</td>\n",
       "      <td>she's not a...</td>\n",
       "      <td>[she, 's, not, a, ...]</td>\n",
       "      <td>she</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LineID Character Movie       Name  \\\n",
       "3    L984       u2    m0    CAMERON    \n",
       "38   L407       u0    m0     BIANCA    \n",
       "39   L406       u2    m0    CAMERON    \n",
       "43   L405       u0    m0     BIANCA    \n",
       "44   L404       u2    m0    CAMERON    \n",
       "\n",
       "                                                                                                                                 Line  \\\n",
       "3                                                                                                                           she okay?   \n",
       "38                                         who knows?  all i've ever heard her say is that she'd dip before dating a guy that smokes.   \n",
       "39                                                                                  so that's the kind of guy she likes? pretty ones?   \n",
       "43   lesbian?  no. i found a picture of jared leto in one of her drawers, so i'm pretty sure she's not harboring same-sex tendencies.   \n",
       "44                                                                                                                     she's not a...   \n",
       "\n",
       "                                                                                                        Segmented_Line  \\\n",
       "3                                                                                                            she okay?   \n",
       "38                                      all i've ever heard her say is that she'd dip before dating a guy that smokes.   \n",
       "39                                                                                so that's the kind of guy she likes?   \n",
       "43  i found a picture of jared leto in one of her drawers, so i'm pretty sure she's not harboring same-sex tendencies.   \n",
       "44                                                                                                      she's not a...   \n",
       "\n",
       "                                                                                                                                      Tokenized_Line  \\\n",
       "3                                                                                                                                     [she, okay, ?]   \n",
       "38                                             [all, i, 've, ever, heard, her, say, is, that, she, 'd, dip, before, dating, a, guy, that, smokes, .]   \n",
       "39                                                                                                 [so, that, 's, the, kind, of, guy, she, likes, ?]   \n",
       "43  [i, found, a, picture, of, jared, leto, in, one, of, her, drawers, ,, so, i, 'm, pretty, sure, she, 's, not, harboring, same-sex, tendencies, .]   \n",
       "44                                                                                                                            [she, 's, not, a, ...]   \n",
       "\n",
       "   Pronoun  \n",
       "3      she  \n",
       "38     she  \n",
       "39     she  \n",
       "43     she  \n",
       "44     she  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b2d7f0f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34941, 8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_lines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "08ddce8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write each movie line sentence with 'he' or 'she' or both to its own line in movie_line_sentences_he_she_both.txt\n",
    "with open('data_processed/movie_line_sentences_he_she_both.txt', 'w') as f:\n",
    "    movie_lines_string = movie_lines['Segmented_Line'].to_string(header=False, index=False)\n",
    "    f.write(movie_lines_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "08541fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write each tokenized movie line sentence with 'he' or 'she' or both to its own line in movie_line_sentences_tokenized_he_she_both.txt\n",
    "with open('data_processed/movie_line_sentences_tokenized_he_she_both.txt', 'w') as f:\n",
    "    movie_lines_string = movie_lines['Tokenized_Line'].to_string(header=False, index=False)\n",
    "    f.write(movie_lines_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "76bfff71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all rows where the movie line sentence contains both 'he' and 'she'\n",
    "movie_lines = movie_lines.loc[movie_lines[\"Pronoun\"] != \"he & she\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6cf5ca3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LineID</th>\n",
       "      <th>Character</th>\n",
       "      <th>Movie</th>\n",
       "      <th>Name</th>\n",
       "      <th>Line</th>\n",
       "      <th>Segmented_Line</th>\n",
       "      <th>Tokenized_Line</th>\n",
       "      <th>Pronoun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L984</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>she okay?</td>\n",
       "      <td>she okay?</td>\n",
       "      <td>[she, okay, ?]</td>\n",
       "      <td>she</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>L407</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>who knows?  all i've ever heard her say is that she'd dip before dating a guy that smokes.</td>\n",
       "      <td>all i've ever heard her say is that she'd dip before dating a guy that smokes.</td>\n",
       "      <td>[all, i, 've, ever, heard, her, say, is, that, she, 'd, dip, before, dating, a, guy, that, smokes, .]</td>\n",
       "      <td>she</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>L406</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>so that's the kind of guy she likes? pretty ones?</td>\n",
       "      <td>so that's the kind of guy she likes?</td>\n",
       "      <td>[so, that, 's, the, kind, of, guy, she, likes, ?]</td>\n",
       "      <td>she</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>L405</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>lesbian?  no. i found a picture of jared leto in one of her drawers, so i'm pretty sure she's not harboring same-sex tendencies.</td>\n",
       "      <td>i found a picture of jared leto in one of her drawers, so i'm pretty sure she's not harboring same-sex tendencies.</td>\n",
       "      <td>[i, found, a, picture, of, jared, leto, in, one, of, her, drawers, ,, so, i, 'm, pretty, sure, she, 's, not, harboring, same-sex, tendencies, .]</td>\n",
       "      <td>she</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>L404</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>she's not a...</td>\n",
       "      <td>she's not a...</td>\n",
       "      <td>[she, 's, not, a, ...]</td>\n",
       "      <td>she</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LineID Character Movie       Name  \\\n",
       "3    L984       u2    m0    CAMERON    \n",
       "38   L407       u0    m0     BIANCA    \n",
       "39   L406       u2    m0    CAMERON    \n",
       "43   L405       u0    m0     BIANCA    \n",
       "44   L404       u2    m0    CAMERON    \n",
       "\n",
       "                                                                                                                                 Line  \\\n",
       "3                                                                                                                           she okay?   \n",
       "38                                         who knows?  all i've ever heard her say is that she'd dip before dating a guy that smokes.   \n",
       "39                                                                                  so that's the kind of guy she likes? pretty ones?   \n",
       "43   lesbian?  no. i found a picture of jared leto in one of her drawers, so i'm pretty sure she's not harboring same-sex tendencies.   \n",
       "44                                                                                                                     she's not a...   \n",
       "\n",
       "                                                                                                        Segmented_Line  \\\n",
       "3                                                                                                            she okay?   \n",
       "38                                      all i've ever heard her say is that she'd dip before dating a guy that smokes.   \n",
       "39                                                                                so that's the kind of guy she likes?   \n",
       "43  i found a picture of jared leto in one of her drawers, so i'm pretty sure she's not harboring same-sex tendencies.   \n",
       "44                                                                                                      she's not a...   \n",
       "\n",
       "                                                                                                                                      Tokenized_Line  \\\n",
       "3                                                                                                                                     [she, okay, ?]   \n",
       "38                                             [all, i, 've, ever, heard, her, say, is, that, she, 'd, dip, before, dating, a, guy, that, smokes, .]   \n",
       "39                                                                                                 [so, that, 's, the, kind, of, guy, she, likes, ?]   \n",
       "43  [i, found, a, picture, of, jared, leto, in, one, of, her, drawers, ,, so, i, 'm, pretty, sure, she, 's, not, harboring, same-sex, tendencies, .]   \n",
       "44                                                                                                                            [she, 's, not, a, ...]   \n",
       "\n",
       "   Pronoun  \n",
       "3      she  \n",
       "38     she  \n",
       "39     she  \n",
       "43     she  \n",
       "44     she  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c928af91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34725, 8)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_lines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d142b728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write each movie line sentence with 'he' or 'she' (but not both) to its own line in movie_line_sentences_he_she.txt\n",
    "with open('data_processed/movie_line_sentences_he_she.txt', 'w') as f:\n",
    "    movie_lines_string = movie_lines['Segmented_Line'].to_string(header=False, index=False)\n",
    "    f.write(movie_lines_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cc60e018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write each tokenized movie line sentence with 'he' or 'she' (but not both) to its own line in movie_line_sentences_tokenized_he_she.txt\n",
    "with open('data_processed/movie_line_sentences_tokenized_he_she.txt', 'w') as f:\n",
    "    movie_lines_string = movie_lines['Tokenized_Line'].to_string(header=False, index=False)\n",
    "    f.write(movie_lines_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e38a0d",
   "metadata": {},
   "source": [
    "## Step 2: Write all 23990 sentences with 'he' (and not both 'he' and 'she') to `data_processed/movie_line_sentences_tokenized_he.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1112adb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new movie_lines_he dataframe containing only movie line sentences with the pronoun 'he' (not both 'he' and 'she')\n",
    "movie_lines_he = movie_lines.loc[movie_lines[\"Pronoun\"] == \"he\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9dff4057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LineID</th>\n",
       "      <th>Character</th>\n",
       "      <th>Movie</th>\n",
       "      <th>Name</th>\n",
       "      <th>Line</th>\n",
       "      <th>Segmented_Line</th>\n",
       "      <th>Tokenized_Line</th>\n",
       "      <th>Pronoun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>L597</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>combination.  i don't know -- i thought he'd be different.  more of a gentleman...</td>\n",
       "      <td>i don't know -- i thought he'd be different.</td>\n",
       "      <td>[i, do, n't, know, --, i, thought, he, 'd, be, different, .]</td>\n",
       "      <td>he</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>L596</td>\n",
       "      <td>u3</td>\n",
       "      <td>m0</td>\n",
       "      <td>CHASTITY</td>\n",
       "      <td>is he oily or dry?</td>\n",
       "      <td>is he oily or dry?</td>\n",
       "      <td>[is, he, oily, or, dry, ?]</td>\n",
       "      <td>he</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>L595</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>he practically proposed when he found out we had the same dermatologist. i mean. dr. bonchowski is great an all, but he's not exactly relevant party conversation.</td>\n",
       "      <td>he practically proposed when he found out we had the same dermatologist.</td>\n",
       "      <td>[he, practically, proposed, when, he, found, out, we, had, the, same, dermatologist, .]</td>\n",
       "      <td>he</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>L595</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>he practically proposed when he found out we had the same dermatologist. i mean. dr. bonchowski is great an all, but he's not exactly relevant party conversation.</td>\n",
       "      <td>dr. bonchowski is great an all, but he's not exactly relevant party conversation.</td>\n",
       "      <td>[dr., bonchowski, is, great, an, all, ,, but, he, 's, not, exactly, relevant, party, conversation, .]</td>\n",
       "      <td>he</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>L571</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>where did he go?  he was just here.</td>\n",
       "      <td>where did he go?</td>\n",
       "      <td>[where, did, he, go, ?]</td>\n",
       "      <td>he</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    LineID Character Movie        Name  \\\n",
       "110   L597       u0    m0      BIANCA    \n",
       "112   L596       u3    m0    CHASTITY    \n",
       "113   L595       u0    m0      BIANCA    \n",
       "115   L595       u0    m0      BIANCA    \n",
       "120   L571       u0    m0      BIANCA    \n",
       "\n",
       "                                                                                                                                                                    Line  \\\n",
       "110                                                                                   combination.  i don't know -- i thought he'd be different.  more of a gentleman...   \n",
       "112                                                                                                                                                   is he oily or dry?   \n",
       "113   he practically proposed when he found out we had the same dermatologist. i mean. dr. bonchowski is great an all, but he's not exactly relevant party conversation.   \n",
       "115   he practically proposed when he found out we had the same dermatologist. i mean. dr. bonchowski is great an all, but he's not exactly relevant party conversation.   \n",
       "120                                                                                                                                  where did he go?  he was just here.   \n",
       "\n",
       "                                                                        Segmented_Line  \\\n",
       "110                                       i don't know -- i thought he'd be different.   \n",
       "112                                                                 is he oily or dry?   \n",
       "113           he practically proposed when he found out we had the same dermatologist.   \n",
       "115  dr. bonchowski is great an all, but he's not exactly relevant party conversation.   \n",
       "120                                                                   where did he go?   \n",
       "\n",
       "                                                                                            Tokenized_Line  \\\n",
       "110                                           [i, do, n't, know, --, i, thought, he, 'd, be, different, .]   \n",
       "112                                                                             [is, he, oily, or, dry, ?]   \n",
       "113                [he, practically, proposed, when, he, found, out, we, had, the, same, dermatologist, .]   \n",
       "115  [dr., bonchowski, is, great, an, all, ,, but, he, 's, not, exactly, relevant, party, conversation, .]   \n",
       "120                                                                                [where, did, he, go, ?]   \n",
       "\n",
       "    Pronoun  \n",
       "110      he  \n",
       "112      he  \n",
       "113      he  \n",
       "115      he  \n",
       "120      he  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_lines_he.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "daef27dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23990, 8)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_lines_he.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d699c60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write each movie line sentence with 'he' (not both 'he' and 'she') to its own line in movie_line_sentences_he.txt\n",
    "with open('data_processed/movie_line_sentences_he.txt', 'w') as f:\n",
    "    movie_lines_he_string = movie_lines_he['Segmented_Line'].to_string(header=False, index=False)\n",
    "    f.write(movie_lines_he_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "869657c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write each tokenized movie line sentence with 'he' (not both 'he' and 'she') to its own line in movie_line_sentences_tokenized_he.txt\n",
    "with open('data_processed/movie_line_sentences_tokenized_he.txt', 'w') as f:\n",
    "    movie_lines_he_string = movie_lines_he['Tokenized_Line'].to_string(header=False, index=False)\n",
    "    f.write(movie_lines_he_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076a2a88",
   "metadata": {},
   "source": [
    "## Step 3: Write all 10735 sentences with 'she' (and not both 'he' and 'she') to `data_processed/movie_line_sentences_tokenized_she.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "046a7af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new movie_lines_she dataframe containing only movie line sentences with the pronoun 'she' (not both 'he' and 'she')\n",
    "movie_lines_she = movie_lines.loc[movie_lines[\"Pronoun\"] == \"she\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c6c18b5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LineID</th>\n",
       "      <th>Character</th>\n",
       "      <th>Movie</th>\n",
       "      <th>Name</th>\n",
       "      <th>Line</th>\n",
       "      <th>Segmented_Line</th>\n",
       "      <th>Tokenized_Line</th>\n",
       "      <th>Pronoun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L984</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>she okay?</td>\n",
       "      <td>she okay?</td>\n",
       "      <td>[she, okay, ?]</td>\n",
       "      <td>she</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>L407</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>who knows?  all i've ever heard her say is that she'd dip before dating a guy that smokes.</td>\n",
       "      <td>all i've ever heard her say is that she'd dip before dating a guy that smokes.</td>\n",
       "      <td>[all, i, 've, ever, heard, her, say, is, that, she, 'd, dip, before, dating, a, guy, that, smokes, .]</td>\n",
       "      <td>she</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>L406</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>so that's the kind of guy she likes? pretty ones?</td>\n",
       "      <td>so that's the kind of guy she likes?</td>\n",
       "      <td>[so, that, 's, the, kind, of, guy, she, likes, ?]</td>\n",
       "      <td>she</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>L405</td>\n",
       "      <td>u0</td>\n",
       "      <td>m0</td>\n",
       "      <td>BIANCA</td>\n",
       "      <td>lesbian?  no. i found a picture of jared leto in one of her drawers, so i'm pretty sure she's not harboring same-sex tendencies.</td>\n",
       "      <td>i found a picture of jared leto in one of her drawers, so i'm pretty sure she's not harboring same-sex tendencies.</td>\n",
       "      <td>[i, found, a, picture, of, jared, leto, in, one, of, her, drawers, ,, so, i, 'm, pretty, sure, she, 's, not, harboring, same-sex, tendencies, .]</td>\n",
       "      <td>she</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>L404</td>\n",
       "      <td>u2</td>\n",
       "      <td>m0</td>\n",
       "      <td>CAMERON</td>\n",
       "      <td>she's not a...</td>\n",
       "      <td>she's not a...</td>\n",
       "      <td>[she, 's, not, a, ...]</td>\n",
       "      <td>she</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LineID Character Movie       Name  \\\n",
       "3    L984       u2    m0    CAMERON    \n",
       "38   L407       u0    m0     BIANCA    \n",
       "39   L406       u2    m0    CAMERON    \n",
       "43   L405       u0    m0     BIANCA    \n",
       "44   L404       u2    m0    CAMERON    \n",
       "\n",
       "                                                                                                                                 Line  \\\n",
       "3                                                                                                                           she okay?   \n",
       "38                                         who knows?  all i've ever heard her say is that she'd dip before dating a guy that smokes.   \n",
       "39                                                                                  so that's the kind of guy she likes? pretty ones?   \n",
       "43   lesbian?  no. i found a picture of jared leto in one of her drawers, so i'm pretty sure she's not harboring same-sex tendencies.   \n",
       "44                                                                                                                     she's not a...   \n",
       "\n",
       "                                                                                                        Segmented_Line  \\\n",
       "3                                                                                                            she okay?   \n",
       "38                                      all i've ever heard her say is that she'd dip before dating a guy that smokes.   \n",
       "39                                                                                so that's the kind of guy she likes?   \n",
       "43  i found a picture of jared leto in one of her drawers, so i'm pretty sure she's not harboring same-sex tendencies.   \n",
       "44                                                                                                      she's not a...   \n",
       "\n",
       "                                                                                                                                      Tokenized_Line  \\\n",
       "3                                                                                                                                     [she, okay, ?]   \n",
       "38                                             [all, i, 've, ever, heard, her, say, is, that, she, 'd, dip, before, dating, a, guy, that, smokes, .]   \n",
       "39                                                                                                 [so, that, 's, the, kind, of, guy, she, likes, ?]   \n",
       "43  [i, found, a, picture, of, jared, leto, in, one, of, her, drawers, ,, so, i, 'm, pretty, sure, she, 's, not, harboring, same-sex, tendencies, .]   \n",
       "44                                                                                                                            [she, 's, not, a, ...]   \n",
       "\n",
       "   Pronoun  \n",
       "3      she  \n",
       "38     she  \n",
       "39     she  \n",
       "43     she  \n",
       "44     she  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_lines_she.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aeb1d5da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10735, 8)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_lines_she.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e9541142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write each movie line sentence with 'she' (not both 'he' and 'she') to its own line in movie_line_sentences_she.txt\n",
    "with open('data_processed/movie_line_sentences_she.txt', 'w') as f:\n",
    "    movie_lines_she_string = movie_lines_she['Segmented_Line'].to_string(header=False, index=False)\n",
    "    f.write(movie_lines_she_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d5672451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write each tokenized movie line sentence with 'she' (not both 'he' and 'she') to its own line in movie_line_sentences_tokenized_she.txt\n",
    "with open('data_processed/movie_line_sentences_tokenized_she.txt', 'w') as f:\n",
    "    movie_lines_she_string = movie_lines_she['Tokenized_Line'].to_string(header=False, index=False)\n",
    "    f.write(movie_lines_she_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44aa167c",
   "metadata": {},
   "source": [
    "## Step 4: To achieve gender parity, use all 10735 of the 'she' sentences, and randomly choose 10735 of the 'he' sentences to be in the dataset for this classification task.\n",
    "\n",
    "Write those 10735 'he' sentences to `data_processed/movie_line_sentences_tokenized_he_selected.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "046b9a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23990 lines with 'he'\n"
     ]
    }
   ],
   "source": [
    "# Check number of movie line sentences with 'he'\n",
    "with open('data_processed/movie_line_sentences_he.txt') as f:\n",
    "    count = 0\n",
    "    for line in f:\n",
    "        count += 1\n",
    "        if count < 1:\n",
    "            print(line)\n",
    "        \n",
    "print(count, \"lines with 'he'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2ee090b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10735 lines with 'she'\n"
     ]
    }
   ],
   "source": [
    "with open('data_processed/movie_line_sentences_she.txt') as f:\n",
    "    count = 0\n",
    "    for line in f:\n",
    "        count += 1\n",
    "        if count < 1:\n",
    "            print(line)\n",
    "        \n",
    "print(count, \"lines with 'she'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "533aab64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10735\n"
     ]
    }
   ],
   "source": [
    "# Take random sample of 10,735 'he' sentences to ensure gender parity\n",
    "# In the future, always work with this same smaller dataset of 'he' sentences,\n",
    "# which we write to data_processed/movie_line_sentences_tokenized_he_selected.txt\n",
    "import random\n",
    "\n",
    "# Generate a set of 10735 random indices between 0 and 23989, inclusive (no repeats)\n",
    "# since 23990 is the total number of 'he' sentences, while we only have 10735 'she' sentences.\n",
    "random_indices = set()\n",
    "while len(random_indices) < 10735:\n",
    "    random_indices.add(random.randint(0, 23989))\n",
    "\n",
    "print(len(random_indices))\n",
    "\n",
    "# Write the 'he' sentences at these 10,735 randomly selected indices to a new txt file\n",
    "with open('data_processed/movie_line_sentences_tokenized_he.txt') as f1:\n",
    "    with open('data_processed/movie_line_sentences_tokenized_he_selected.txt', 'w') as f2:\n",
    "        count = 0\n",
    "        for line in f1:\n",
    "            count += 1\n",
    "            if count in random_indices:\n",
    "                f2.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979f42dc",
   "metadata": {},
   "source": [
    "## Step 5: Build a vocabulary of all the words in the 10735 'he' sentences and 10735 'she' sentences.\n",
    "\n",
    "* Write this vocabulary to `data_processed/movie_line_sentences_vocab.txt`, where each vocab word should appear on its own line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b41a91d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "    \n",
    "def build_vocab(vocab_file_name, file1_name, file2_name=None):\n",
    "    \"\"\"\n",
    "    takes in a vocab_file_name string, a file1_name string, and an optional file2_name string\n",
    "    builds a vocabulary from the sentences in the files with file1_name and file2_name\n",
    "    writes each vocab word to its own line in a txt file with vocab_file_name\n",
    "    returns a Counter with the vocab words and their counts\n",
    "    \"\"\"\n",
    "    file1_sentences = read_file_lines(file1_name)\n",
    "\n",
    "    vocab = Counter()\n",
    "    vocab = build_vocab_from_sentences(file1_sentences, vocab)\n",
    "    \n",
    "    if file2_name:\n",
    "        file2_sentences = read_file_lines(file2_name)\n",
    "        vocab = build_vocab_from_sentences(file2_sentences, vocab)\n",
    "\n",
    "    print(len(vocab))\n",
    "\n",
    "    # write vocabulary to txt file, with the most common vocab words appearing first\n",
    "    with open(vocab_file_name, 'w') as f:\n",
    "        for word, freq in vocab.most_common():\n",
    "            f.write(word + \"\\n\")\n",
    "    return vocab\n",
    "\n",
    "def read_file_lines(filename):\n",
    "    \"\"\"\n",
    "    helper function for build_vocab\n",
    "    takes in a string for a filename\n",
    "    return a list of the lines in the file\n",
    "    \"\"\"\n",
    "    with open(filename, 'r') as f:\n",
    "        file_lines = f.readlines()\n",
    "    return file_lines\n",
    "\n",
    "def build_vocab_from_sentences(sentences, vocab):\n",
    "    \"\"\"\n",
    "    helper function for build_vocab\n",
    "    takes in a list of sentences that are strings that look like \"[The, dog, ate, food, .]\",\n",
    "    and a Counter of the words in our vocab so far\n",
    "    \"\"\"\n",
    "    for sentence in sentences:\n",
    "        sentence = sentence.strip()\n",
    "        sentence = sentence.strip('[]')     # remove brackets (present due to the python word tokens list data structure)\n",
    "        for word in sentence.split():\n",
    "            if word[-1] == ',':\n",
    "                word = word[:-1]    # remove comma after the word (the comma acted as a delimiter for the list)\n",
    "            vocab[word] += 1\n",
    "    return vocab\n",
    "\n",
    "# for example:\n",
    "# build vocabulary from all the sentences in the 'he_selected' and 'she' files\n",
    "# vocab = build_vocab('data_processed/movie_line_sentences_vocab.txt',\n",
    "#                     'data_processed/movie_line_sentences_tokenized_he_selected.txt',\n",
    "#                     'data_processed/movie_line_sentences_tokenized_she.txt')\n",
    "# print(vocab.most_common(105))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995009a9",
   "metadata": {},
   "source": [
    "## Step 6: Limit the vocab size to the top 10000 vocab words after removing the 100 most common stop words.\n",
    "\n",
    "* 'he' and 'she' are included in the 100 most common stop words, so this also helps us avoid using 'he' or 'she' as features.\n",
    "* 'he' is generally used to describe men and 'she' is generally used to describe women, so we didn't want to include these two pronouns as features in our model, since it would not tell us much about the words used to describe male characters versus female characters if 'he' and 'she' were the most important features in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e2fda64",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "\n",
    "def limit_vocab(vocab_file, vocab_size, num_stop_words):\n",
    "    \"\"\"\n",
    "    takes in a string for the vocab_file name,\n",
    "    the vocab_size we want to limit our vocab to,\n",
    "    and the num_stop_words we want to exclude from our vocab\n",
    "    \n",
    "    returns a list of vocab_size number of vocab words,\n",
    "    and also a dictionary that maps each of those vocab words to its index in the vocab words list\n",
    "    \"\"\"\n",
    "    start_index = num_stop_words\n",
    "    end_index = start_index + vocab_size\n",
    "\n",
    "    with open(vocab_file) as f:\n",
    "        vocab_words = [w.strip() for w in islice(f, start_index, end_index)]\n",
    "        vocab_words_to_indices = dict([(w, i) for (i, w) in enumerate(vocab_words)])\n",
    "\n",
    "    print(len(vocab_words))\n",
    "    print(vocab_words[:5]) # see first 5 most common vocab words (these should be the last 5 words printed out in the last cell)\n",
    "    print(len(vocab_words_to_indices))\n",
    "    return vocab_words, vocab_words_to_indices\n",
    "\n",
    "# for example:\n",
    "# limit the vocab size to the top 10000 vocab words after removing the 100 most common words as stop words\n",
    "# 'he' and 'she' are included in the 100 most common stop words, so we also don't use 'he' or 'she' as features\n",
    "# vocab_words, vocab_words_to_indices = limit_vocab('data_processed/movie_line_sentences_vocab.txt', 10000, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabd0d66",
   "metadata": {},
   "source": [
    "## Step 7: For each movie line sentence, obtain a feature vector.\n",
    "\n",
    "* Use the counts of each unigram in the sentence as bag-of-words features.\n",
    "* Populate a scikit-learn sparse feature matrix with the feature vectors for all 10735 'he' sentences and 10735 'she' sentences.\n",
    "* The first 10735 feature vectors of the feature matrix are for the 'he' sentences, and the last 10735 feature vectors are for the 'she' sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b89d43a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a feature matrix consisting of a feature vector for each sentence\n",
    "# Use counts of unigrams as bag-of-words features\n",
    "from collections import Counter\n",
    "from scipy import sparse\n",
    "from scipy.sparse import vstack\n",
    "\n",
    "def get_feature_matrix(movie_lines_file, class_size, vocab_dict):\n",
    "    \"\"\"\n",
    "    takes in a txt file of movie line sentences,\n",
    "    the size of each class (for example, the number of sentences truly labeled as 'he') in our dataset,\n",
    "    and also a dictionary mapping vocab words (which are the features) to their feature indices\n",
    "    returns a sparse lil matrix as the feature matrix for all the sentences in the movie line sentence file\n",
    "    \"\"\"\n",
    "    num_features = len(vocab_dict) # TODO: check if correct\n",
    "    X = sparse.lil_matrix((class_size, num_features), dtype='uint8')\n",
    "    with open(movie_lines_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        line_index = 0\n",
    "        for line in lines:\n",
    "            for feature_index, value in get_features(line, vocab_dict):\n",
    "                # add features to feature vector at the index where they belong, according to their the vocab word index\n",
    "                X[line_index,feature_index] = value\n",
    "            line_index += 1\n",
    "    return X\n",
    "\n",
    "def get_features(movie_line_sentence, vocab_dict):\n",
    "    \"\"\"\n",
    "    takes in a movie line sentence\n",
    "    and also a dictionary mapping vocab words (which are the features) to their feature indices\n",
    "    returns a feature vector of bag-of-words features (counts of unigrams) for the sentence\n",
    "    \"\"\"\n",
    "    # create counter of the words in the movie line sentence\n",
    "    word_counter = Counter()\n",
    "    movie_line_sentence = movie_line_sentence.strip()\n",
    "    movie_line_sentence = movie_line_sentence.strip('[]')   # remove brackets (present due to the python word tokens list data structure)\n",
    "    for word in movie_line_sentence.split():\n",
    "        if word[-1] == ',':\n",
    "            word = word[:-1]     # remove comma after the word (the comma acted as a delimiter for the list)\n",
    "        word_counter[word] += 1\n",
    "    \n",
    "    # here, the features are the counts of unigrams (single words) in the sentence\n",
    "    # we're populating a sparse matrix, so only add non-zero counts to our features list\n",
    "    features = []\n",
    "    for word in word_counter:\n",
    "        # only include counts for words in our vocab\n",
    "        if word in vocab_dict:\n",
    "            word_feature_index = vocab_dict[word]\n",
    "            word_count = word_counter[word]\n",
    "            features.append((word_feature_index, word_count))   # need vocab word index to add features to feature index at the index where they belong\n",
    "    return features\n",
    "\n",
    "# for example:\n",
    "# get a feature matrix for the 'he' sentences, and a separate feature matrix for the 'she' sentences\n",
    "# class_size = 10735    # 10735 'he' sentences and 10735 'she' sentences\n",
    "# feature_matrix_he = get_feature_matrix('data_processed/movie_line_sentences_tokenized_he_selected.txt', class_size, vocab_words_to_indices)\n",
    "# feature_matrix_she = get_feature_matrix('data_processed/movie_line_sentences_tokenized_she.txt', class_size, vocab_words_to_indices)\n",
    "\n",
    "# # concatenate the two matrices\n",
    "# # put the 'he' sentence feature vectors first (in the first half of the feature matrix),\n",
    "# # and then the 'she' sentence feature vectors after (in the second half of the feature matrix).\n",
    "# feature_matrix = vstack([feature_matrix_he, feature_matrix_she]).toarray()\n",
    "\n",
    "# print(feature_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be079b53",
   "metadata": {},
   "source": [
    "## Step 8: Create a ground truth list of 0 and 1 labels, where the first 10735 labels are 0's, and the last 10735 labels are 1's.\n",
    "* 0 is for 'he'\n",
    "* 1 is for 'she'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33d44544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping for binary labels — 0 is for 'he', and 1 is for 'she'\n",
    "# labels = {0: 'he', 1: 'she'}\n",
    "\n",
    "# class_size = 10735 # 10735 'he' sentences and 10735 'she' sentences\n",
    "\n",
    "# # A list of ground truth binary labels for the two classes ('he' and 'she') \n",
    "# # We'll put the 'he' sentences first, and then the 'she' sentences after,\n",
    "# # since that's the same as the order in which our feature vectors are stored in the feature matrix.\n",
    "# data_labels = [0] * class_size + [1] * class_size\n",
    "# print(data_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a202a79",
   "metadata": {},
   "source": [
    "## Step 9: Create a scikit-learn Multinomial Bayes Naive Classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed94b6d6",
   "metadata": {},
   "source": [
    "## Step 10: Perform 10-fold cross validation.\n",
    "* Use scikit-learn's `cross_val_predict` function, passing in the feature matrix, the ground truth label list, and 10 as the number of folds.\n",
    "* Write binary predictions (0 or 1) and prediction probabilities for all 10735 'he' sentences and 10735 'she' sentences to `data_processed/movie_line_sentences_predictions.txt` file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "594857c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12901\n",
      "10000\n",
      "['``', 'will', 'says', 'time', \"''\"]\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "def do_classification(vocab_file_name, vocab_size, num_stop_words,\n",
    "                      file1_tokenized_sentences_name, file2_tokenized_sentences_name,\n",
    "                      class_size, classes,\n",
    "                      predictions_file_name,\n",
    "                      num_folds):\n",
    "    \"\"\"\n",
    "    takes in vocab_file_name for name of txt file to write vocab to,\n",
    "    vocab_size to limit vocab to, num_stop_words to exclude from vocab,\n",
    "    file1_tokenized_sentences_name string representing name of first file of sentences to classify,\n",
    "    file2_tokenized_sentences_name string representing name of second file of sentences to classify,\n",
    "    class_size (for example, the number of sentences truly labeled as 'he') in our dataset,\n",
    "    classes two-element list of the class labels for file1 and file2 (classes[0] is class for file1 sentences; classes[1] is class for file2 sentences)\n",
    "    predictions_file_name for name of txt file to write classification predictions to,\n",
    "    num_folds to use in cross-validation\n",
    "    \"\"\"\n",
    "    # build vocabulary from all the sentences in the 'he_selected' and 'she' files\n",
    "    vocab = build_vocab(vocab_file_name, file1_tokenized_sentences_name, file2_tokenized_sentences_name)\n",
    "\n",
    "    # limit vocab to the vocab_size after removing the num_stop_words most common words as stop words\n",
    "    vocab_words, vocab_words_to_indices = limit_vocab(vocab_file_name, vocab_size, num_stop_words)\n",
    "    \n",
    "    # get feature matrix for each file\n",
    "    file1_feature_matrix = get_feature_matrix(file1_tokenized_sentences_name, class_size, vocab_words_to_indices)\n",
    "    file2_feature_matrix = get_feature_matrix(file2_tokenized_sentences_name, class_size, vocab_words_to_indices)\n",
    "\n",
    "    # concatenate the two matrices\n",
    "    # put the file1 sentence feature vectors first (in the first half of the feature matrix),\n",
    "    # and then the file2 sentence feature vectors after (in the second half of the feature matrix).\n",
    "    feature_matrix = vstack([file1_feature_matrix, file2_feature_matrix]).toarray()\n",
    "\n",
    "    # get a list of ground truth binary labels for the two classes (whose labels are defined by the two-element list classes)\n",
    "    # put in the same file1 then file2 order as our feature matrix\n",
    "    data_labels = [classes[0]] * class_size + [classes[1]] * class_size\n",
    "\n",
    "    # create Multinomial Naive Bayes classifier using scikit learn\n",
    "    classifier = MultinomialNB()\n",
    "\n",
    "    # Perform 10-fold cross validation on the training data,\n",
    "    # getting predictions (and probabilities) for each instance in the training set\n",
    "    test_predictions = cross_val_predict(classifier, feature_matrix, data_labels, cv=num_folds, method='predict')\n",
    "    test_probabilities = cross_val_predict(classifier, feature_matrix, data_labels, cv=num_folds, method='predict_proba')\n",
    "\n",
    "    # write predictions and prediction probabilities to txt file\n",
    "    # each movie line sentence prediction is on its own line, with a space separating the predicted label from the prediction probability\n",
    "    with open(predictions_file_name, 'w') as f:\n",
    "        for i in range(len(test_predictions)):\n",
    "            f.write(str(test_predictions[i]) + \" \" + str(max(test_probabilities[i])) + \"\\n\")\n",
    "            \n",
    "# class_size is 10735 because 10735 'he' sentences and 10735 'she' sentences\n",
    "# use 10 folds in cross-validation\n",
    "do_classification('data_processed/movie_line_sentences_vocab.txt', 10000, 100,\n",
    "                  'data_processed/movie_line_sentences_tokenized_he_selected.txt',\n",
    "                  'data_processed/movie_line_sentences_tokenized_she.txt',\n",
    "                  10735, [0, 1],\n",
    "                  'data_processed/movie_line_sentences_predictions.txt',\n",
    "                  10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20dcdbd",
   "metadata": {},
   "source": [
    "## Step 11: Calculate accuracy, precision, recall, and F1\n",
    "* By comparing the binary predictions in `data_processed/movie_line_sentences_predictions.txt` to the ground truth labels in our ground truth label list (`data_labels`), matching movie line sentences by their index (which should be the same for the same sentence in the prediction file and the ground truth label list)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08d112d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'truePositives': 7073, 'trueNegatives': 4664, 'falsePositives': 6071, 'falseNegatives': 3662, 'accuracy': 0.5466697717745692, 'precision': 0.5381162507608034, 'recall': 0.6588728458313926, 'f1': 0.5924033669751665}\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def evaluate_classifier_predictions(ground_truth_labels, predictions_file_name):\n",
    "    \"\"\"\n",
    "    takes in a list of ground truth labels that match the order of the sentences in the predictions file,\n",
    "    and a predictions_file_name\n",
    "    \n",
    "    reports the accuracy, precision, recall, and F1 scores of the classifier\n",
    "    \"\"\"\n",
    "    with open(predictions_file_name) as f:\n",
    "        c = Counter()\n",
    "        sentence_num = 0\n",
    "        for line in f: \n",
    "            values = line.rstrip('\\n').split()\n",
    "            prediction = int(values[0])  # the 0's and 1's will be read in as strings, so need to convert to ints\n",
    "\n",
    "            c[(prediction, ground_truth_labels[sentence_num])] += 1\n",
    "            sentence_num += 1\n",
    "\n",
    "        if sum(c.values()) < len(ground_truth_labels):\n",
    "            warnings.warn(\"Missing {} predictions\".format(len(ground_truth_labels) - sum(c.values())), UserWarning)\n",
    "\n",
    "        # treat 'she' (1) as the positive class, and 'he' (0) as the negative class\n",
    "        tp = c[(1, 1)] # predicted 'she', and sentence was actually referring to 'she' \n",
    "        tn = c[(0, 0)] # predicted 'he', and sentence was actually referring to 'he'\n",
    "        fp = c[(1, 0)] # predicted 'she', and sentence was actually referring to 'he' \n",
    "        fn = c[(0, 1)] # predicted 'he', and sentence was actually referring to 'she' \n",
    "    \n",
    "        accuracy  = (tp + tn) / sum(c.values())\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "\n",
    "        results = {\"truePositives\": tp, \"trueNegatives\": tn, \"falsePositives\": fp, \"falseNegatives\": fn,\n",
    "                   \"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
    "        print(results)\n",
    "\n",
    "\n",
    "# get a list of ground truth binary labels for the two classes (whose labels are defined by the two-element list classes)\n",
    "# put in the same file1 then file2 order as our feature matrix\n",
    "classes = [0, 1]\n",
    "class_size = 10735\n",
    "data_labels = [classes[0]] * class_size + [classes[1]] * class_size\n",
    "evaluate_classifier_predictions(data_labels, 'data_processed/movie_line_sentences_predictions.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbb1150",
   "metadata": {},
   "source": [
    "## Classifying with a Dataset Restricted to Sentences With At Least 15 Words\n",
    "\n",
    "* The dataset has a lot of very short sentences, which make for very sparse feature vectors (vectors with lots of 0's), which is why the classifier might have difficult labeling sentences as either about a 'he' or about a 'she'. Let's try restricting the dataset even further to sentences that have at least 15 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f9f52dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6120\n"
     ]
    }
   ],
   "source": [
    "# Write movie line sentences with 'he' with at least 15 words to new txt file\n",
    "with open('data_processed/movie_line_sentences_tokenized_he.txt') as f1:\n",
    "    with open('data_processed/movie_line_sentences_tokenized_he_15_words.txt', 'w') as f2:\n",
    "        count = 0\n",
    "        for line in f1:\n",
    "            if len(line.split()) >= 15:\n",
    "                count += 1\n",
    "                f2.write(line)\n",
    "        \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c8e6cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2443\n"
     ]
    }
   ],
   "source": [
    "# Write movie line sentences with 'she' with at least 15 words to new txt file\n",
    "with open('data_processed/movie_line_sentences_tokenized_she.txt') as f1:\n",
    "    with open('data_processed/movie_line_sentences_tokenized_she_15_words.txt', 'w') as f2:\n",
    "        count = 0\n",
    "        for line in f1:\n",
    "            if len(line.split()) >= 15:\n",
    "                count += 1\n",
    "                f2.write(line)\n",
    "        \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4005139f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2443\n",
      "2443\n"
     ]
    }
   ],
   "source": [
    "# Take random sample of 2443 'he' sentences to ensure gender parity\n",
    "# In the future, always work with this same smaller dataset of 'he' sentences,\n",
    "# which we write to data_processed/movie_line_sentences_tokenized_he_15_words_selected.txt\n",
    "import random\n",
    "\n",
    "# Generate a set of 2443 random indices between 0 and 2442, inclusive (no repeats)\n",
    "# since 6120 is the total number of 'he' sentences, while we only have 2443 'she' sentences.\n",
    "random_indices = set()\n",
    "while len(random_indices) < 2443:\n",
    "    random_indices.add(random.randint(0, 2442))\n",
    "\n",
    "print(len(random_indices))\n",
    "\n",
    "# Write the 'he' sentences at these 2443 randomly selected indices to a new txt file\n",
    "with open('data_processed/movie_line_sentences_tokenized_he_15_words.txt') as f1:\n",
    "    with open('data_processed/movie_line_sentences_tokenized_he_15_words_selected.txt', 'w') as f2:\n",
    "        count = 0\n",
    "        for line in f1:\n",
    "            if count in random_indices:\n",
    "                count += 1\n",
    "                f2.write(line)\n",
    "                \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cbd0f804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8895\n",
      "8795\n",
      "['off', 'were', 'time', 'over', \"'ve\"]\n",
      "8795\n"
     ]
    }
   ],
   "source": [
    "# Create feature matrices and run classifier again\n",
    "do_classification('data_processed/movie_line_sentences_15_words_vocab.txt', 10000, 100,\n",
    "                  'data_processed/movie_line_sentences_tokenized_he_15_words_selected.txt',\n",
    "                  'data_processed/movie_line_sentences_tokenized_she_15_words.txt',\n",
    "                  2443, [0, 1],\n",
    "                  'data_processed/movie_line_sentences_15_words_predictions.txt',\n",
    "                  10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b76dec21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'truePositives': 1547, 'trueNegatives': 1259, 'falsePositives': 1184, 'falseNegatives': 896, 'accuracy': 0.5742939009414654, 'precision': 0.5664591724642988, 'recall': 0.6332378223495702, 'f1': 0.5979899497487438}\n"
     ]
    }
   ],
   "source": [
    "# get a list of ground truth binary labels for the two classes (whose labels are defined by the two-element list classes)\n",
    "# put in the same file1 then file2 order as our feature matrix\n",
    "classes = [0, 1]\n",
    "class_size = 2443\n",
    "data_labels = [classes[0]] * class_size + [classes[1]] * class_size\n",
    "evaluate_classifier_predictions(data_labels, 'data_processed/movie_line_sentences_15_words_predictions.txt', )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b15f8e3",
   "metadata": {},
   "source": [
    "## Next steps?\n",
    "* Find the most important features used by our classifier and analyze them:\n",
    "    - https://stackoverflow.com/questions/50526898/how-to-get-feature-importance-in-naive-bayes\n",
    "    - https://stackoverflow.com/questions/29867367/sklearn-multinomial-nb-most-informative-features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257998c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
